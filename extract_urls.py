"""
PDF URL Extractor for Maturita Portal

This script extracts PDF URLs from text input and saves them to a structured text file.
The URLs are parsed to extract book titles and author names for use in the portal.
"""

import re
import os
from urllib.parse import unquote

# PDF URLs provided
PDF_URLS = [
    "https://www.milujemecestinu.cz/files/tournaments/112/Zdenek_Jirotka_Saturnin.pdf",
    "https://www.milujemecestinu.cz/files/tournaments/29/Karel_Capek_-_R._U._R..pdf",
    "https://www.milujemecestinu.cz/files/tournaments/83/Francis_Scott_Fitzgerald_Velky_Gatsby.pdf",
    "https://www.milujemecestinu.cz/files/tournaments/131/Moliere_Lakomec.pdf",
    "https://www.milujemecestinu.cz/files/tournaments/157/Erich_Maria_Remarque_Na_zapadni_fronte_klid.pdf",
    "https://www.milujemecestinu.cz/files/tournaments/68/John_Steinbeck_O_mysich_a_lidech.pdf",
    "https://www.milujemecestinu.cz/files/tournaments/81/Antoine_de_Saint_Exupery_Maly_princ.pdf",
]


def extract_info_from_url(url: str) -> dict:
    """
    Extract author name and book title from PDF URL.
    
    Args:
        url: The PDF URL to parse
        
    Returns:
        Dictionary with url, filename, author, title, and slug
    """
    # Get the filename from URL
    filename = url.split("/")[-1]
    
    # Remove .pdf extension
    name_part = filename.replace(".pdf", "")
    
    # URL decode the filename
    name_part = unquote(name_part)
    
    # Replace underscores with spaces
    name_part = name_part.replace("_", " ")
    
    # Clean up multiple spaces and dashes
    name_part = re.sub(r'\s+', ' ', name_part).strip()
    name_part = re.sub(r'\s*-\s*', ' - ', name_part)
    
    # Try to split author and title
    # Common patterns: "Author Title", "Author - Title"
    if " - " in name_part:
        parts = name_part.split(" - ", 1)
        author = parts[0].strip()
        title = parts[1].strip()
    else:
        # Try to intelligently split based on common patterns
        # This is a simplified approach
        words = name_part.split()
        
        # Known book titles at the end
        known_titles = {
            "Saturnin": -1,
            "Lakomec": -1,
            "Gatsby": -2,  # "Velky Gatsby"
        }
        
        # Find where author ends and title begins
        author_words = []
        title_words = []
        found_title = False
        
        for i, word in enumerate(words):
            if not found_title:
                # Check if this could be start of title
                if word[0].isupper() and i > 1:
                    # Could be title start - check if previous words were all name parts
                    if any(key.lower() in word.lower() for key in ['Saturnin', 'R.', 'Gatsby', 'Lakomec', 'Na', 'O', 'Maly']):
                        found_title = True
                        title_words.append(word)
                    else:
                        author_words.append(word)
                else:
                    author_words.append(word)
            else:
                title_words.append(word)
        
        # If we didn't find a split, make a guess
        if not title_words:
            # Assume last 1-3 words are the title
            if len(words) > 3:
                author_words = words[:-2]
                title_words = words[-2:]
            elif len(words) > 2:
                author_words = words[:-1]
                title_words = words[-1:]
            else:
                author_words = words[:1]
                title_words = words[1:]
        
        author = " ".join(author_words)
        title = " ".join(title_words)
    
    # Generate slug for file naming
    slug = title.lower()
    slug = re.sub(r'[^a-z0-9\s]', '', slug)
    slug = slug.replace(" ", "-")
    slug = re.sub(r'-+', '-', slug)
    
    return {
        "url": url,
        "filename": filename,
        "author": author,
        "title": title,
        "slug": slug
    }


def main():
    """Main function to process URLs and generate output file."""
    
    output_dir = os.path.dirname(os.path.abspath(__file__))
    output_file = os.path.join(output_dir, "book_urls.txt")
    
    print("=" * 60)
    print("PDF URL Extractor for Maturita Portal")
    print("=" * 60)
    print()
    
    books = []
    
    for url in PDF_URLS:
        info = extract_info_from_url(url)
        books.append(info)
        print(f"ðŸ“š {info['title']}")
        print(f"   Author: {info['author']}")
        print(f"   Slug: {info['slug']}")
        print(f"   URL: {url}")
        print()
    
    # Write to output file
    with open(output_file, "w", encoding="utf-8") as f:
        f.write("# Book URLs for Maturita Portal\n")
        f.write("# Generated by extract_urls.py\n")
        f.write("# Format: title | author | slug | url\n")
        f.write("=" * 80 + "\n\n")
        
        for book in books:
            f.write(f"Title: {book['title']}\n")
            f.write(f"Author: {book['author']}\n")
            f.write(f"Slug: {book['slug']}\n")
            f.write(f"Filename: {book['filename']}\n")
            f.write(f"URL: {book['url']}\n")
            f.write("-" * 40 + "\n\n")
    
    print("=" * 60)
    print(f"âœ… Extracted {len(books)} book URLs")
    print(f"ðŸ“„ Output saved to: {output_file}")
    print("=" * 60)
    
    return books


if __name__ == "__main__":
    main()
